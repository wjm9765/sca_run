import os
import sys
import time
import argparse
import asyncio
import torch
import numpy as np
import librosa
import soundfile as sf

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (src í´ë”ê°€ ìˆëŠ” ìœ„ì¹˜)
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# íŒ¨í‚¤ì§€ ì„í¬íŠ¸
from src.inference import Qwen3OmniFullDuplexEngine, EngineConfig
from sca_run.src.utils.client_utils import log 
from transformers import Qwen3OmniMoeForConditionalGeneration, Qwen3OmniMoeProcessor

# ë©”ëª¨ë¦¬ ì„¤ì •
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

def load_audio_file(file_path, target_sr=16000):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Audio file not found: {file_path}")
    log("info", f"Loading audio file: {file_path}")
    audio, sr = librosa.load(file_path, sr=target_sr, mono=True)
    return audio, sr

async def run_sequential_test(engine, chunks, processor, device, wait_per_chunk=1.5):
    """
    ìˆœì°¨ì  í…ŒìŠ¤íŠ¸ ë£¨í”„:
    1. ì²­í¬ 1ê°œ ë³´ëƒ„
    2. ì¼ì • ì‹œê°„(wait_per_chunk) ë™ì•ˆ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ì§€ ëŒ€ê¸°í•˜ë©° ìˆ˜ì§‘
    3. ë‹¤ìŒ ì²­í¬ ì§„í–‰
    """
    all_output_audio = []
    
    log("info", f"ğŸ¬ Starting Sequential Test: {len(chunks)} chunks")
    log("info", f"â±ï¸ Wait time per chunk: {wait_per_chunk}s (Debugging Mode)")

    for i, chunk in enumerate(chunks):
        # -------------------------------------------------
        # 1. ì…ë ¥ ì²˜ë¦¬ ë° ì „ì†¡
        # -------------------------------------------------
        if len(chunk) < 5120: # 0.32s Padding
            chunk = np.pad(chunk, (0, 5120 - len(chunk)))
        
        features = processor.feature_extractor(
            [chunk], return_tensors="pt", sampling_rate=16000, padding=False,
        )
        input_features = features.input_features.to(device).to(engine.model.dtype)
        if input_features.dim() == 5 and input_features.shape[-1] == 1:
                input_features = input_features.squeeze(-1)


        # NaN ì²´í¬
        if torch.isnan(input_features).any():
            input_features = torch.nan_to_num(input_features, nan=0.0)

        log("info", f"--------------------------------------------------")
        log("info", f"ğŸ“¡ [Step {i}] Pushing Chunk ({input_features.shape})")
        
        # ì—”ì§„ì— ì˜¤ë””ì˜¤ íˆ¬ì…
        await engine.push_audio(input_features)
        
        # -------------------------------------------------
        # 2. ê²°ê³¼ ìˆ˜ì§‘ (Polling)
        # -------------------------------------------------
        # ë¹„ë™ê¸° Receiver ëŒ€ì‹ , ì—¬ê¸°ì„œ ì§ì ‘ ì¼ì • ì‹œê°„ë™ì•ˆ íë¥¼ í„¸ì–´ë´…ë‹ˆë‹¤.
        start_wait = time.time()
        chunk_received_count = 0
        
        current_wait = wait_per_chunk

        while time.time() - start_wait < current_wait:
            out_bytes = await engine.get_audio_output()
            
            if out_bytes:
                out_np = np.frombuffer(out_bytes, dtype=np.int16).astype(np.float32) / 32767.0
                all_output_audio.append(out_np)
                chunk_received_count += 1
                sys.stdout.write(f"ğŸµ") 
                sys.stdout.flush()
                # â˜… ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ë¼ë„ ë°›ì•˜ìœ¼ë©´, ì—°ì†ëœ ì˜¤ë””ì˜¤ê°€ ë” ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëŒ€ê¸° ì‹œê°„ ì—°ì¥
                start_wait = time.time() 
                current_wait = 1.0 # ì¶”ê°€ ë°ì´í„° ëŒ€ê¸° ì‹œê°„ì€ ì§§ê²Œ
            else:
                await asyncio.sleep(0.05) # 0.01ì€ ë„ˆë¬´ ë¹ ë¦„, CPU ë¶€í•˜ ì¡°ì ˆ
        
        print("") # ì¤„ë°”ê¿ˆ
        if chunk_received_count == 0:
            log("warning", f"âš ï¸ [Step {i}] No audio response received.")
        else:
            log("info", f"âœ… [Step {i}] Received {chunk_received_count} audio fragments.")

    return all_output_audio

async def main_async():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model-path", type=str, default="Qwen/Qwen3-Omni-30B-A3B-Instruct")
    parser.add_argument("--input-file", type=str, required=True)
    parser.add_argument("--output-file", type=str, default="debug_output.wav")
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--wait", type=float, default=2.0, help="Wait seconds per chunk for debugging")
    args = parser.parse_args()

    # 1. ëª¨ë¸ ë¡œë“œ
    log("info", f"Loading Model from {args.model_path}...")
    model = Qwen3OmniMoeForConditionalGeneration.from_pretrained(
        args.model_path,
        device_map="auto",
        dtype=torch.bfloat16,
        attn_implementation='flash_attention_2',
        trust_remote_code=True
    )
    processor = Qwen3OmniMoeProcessor.from_pretrained(args.model_path, trust_remote_code=True)
    
    # 2. ì—”ì§„ ì´ˆê¸°í™” (ìˆ˜ì •ëœ ë¡œì§ ì ìš©ë¨)
    config = EngineConfig()
    engine = Qwen3OmniFullDuplexEngine(model, processor.tokenizer, config)
    
    # 3. ì˜¤ë””ì˜¤ ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš© ì§§ì€ ì»·)
    full_audio, sr = load_audio_file(args.input_file, target_sr=16000)
    
    # ë””ë²„ê¹…ì„ ìœ„í•´ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ 60ì´ˆë§Œ ìë¦„
    MAX_SEC = 32
    if len(full_audio) > MAX_SEC * sr:
        full_audio = full_audio[:MAX_SEC * sr]
        log("info", f"âœ‚ï¸ Audio cropped to {MAX_SEC}s for debugging")

    chunk_size = int(sr * 0.32)
    chunks = [full_audio[i:i + chunk_size] for i in range(0, len(full_audio), chunk_size)]
    
    # 4. ì—”ì§„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ ë£¨í”„ ì‹¤í–‰)
    await engine.start()
    
    try:
        # 5. ìˆœì°¨ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        collected_audio_parts = await run_sequential_test(
            engine, chunks, processor, args.device, wait_per_chunk=args.wait,
        )
        
        # 6. ê²°ê³¼ ì €ì¥
        if collected_audio_parts:
            final_audio = np.concatenate(collected_audio_parts)
            OUTPUT_SR = 24000
            sf.write(args.output_file, final_audio, OUTPUT_SR)
            log("info", f"ğŸ’¾ Saved output to {args.output_file} ({len(final_audio)/OUTPUT_SR:.2f}s)")
        else:
            log("error", "âŒ No audio generated at all.")

    except Exception as e:
        log("error", f"Critical Error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await engine.stop()
        log("info", "Test Finished.")

if __name__ == "__main__":
    try:
        asyncio.run(main_async())
    except KeyboardInterrupt:
        log("info", "Interrupted by user.")