<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>sca_run mic</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 24px; }
    button { padding: 10px 14px; margin-right: 10px; }
    #status { margin-top: 12px; }
    #log { margin-top: 12px; white-space: pre-wrap; background: #f6f6f6; padding: 12px; border-radius: 8px; min-height: 120px; }
    .small { font-size: 12px; opacity: 0.8; }
  </style>
</head>
<body>
  <h3>sca_run</h3>
  <div>
    <button id="runBtn">Start Qwen</button>
    <button id="micBtn" disabled>Mic ON</button>
  </div>
  <div id="status" class="small">Idle. Click 'Start Qwen' to initialize model.</div>
  <div id="log" class="small"></div>

<script>
(() => {
  const micBtn = document.getElementById('micBtn');
  const runBtn = document.getElementById('runBtn');
  const statusEl = document.getElementById('status');
  const logEl = document.getElementById('log');

  let audioCtx = null;
  let mediaStream = null;
  let sourceNode = null;
  let processorNode = null;
  let zeroGain = null;

  let ws = null;
  let sending = false;
  let micOn = false;
  
  // Speaker is always ON by default
  let speakerOn = true;

  let playCtx = null;
  let pendingAudioMeta = null;

  // Server expects 16kHz mono PCM16LE by default (see config/default.toml)
  const TARGET_SR = 16000;

  function setStatus(s) { statusEl.textContent = s; }
  function log(s) {
    logEl.textContent = (logEl.textContent + s + "\n").slice(-4000);
    logEl.scrollTop = logEl.scrollHeight;
  }

  function downsampleBuffer(buffer, inSampleRate, outSampleRate) {
    if (outSampleRate === inSampleRate) return buffer;
    if (outSampleRate > inSampleRate) throw new Error('outSampleRate must be <= inSampleRate');

    const ratio = inSampleRate / outSampleRate;
    const newLen = Math.round(buffer.length / ratio);
    const result = new Float32Array(newLen);

    let offsetResult = 0;
    let offsetBuffer = 0;
    while (offsetResult < result.length) {
      const nextOffsetBuffer = Math.round((offsetResult + 1) * ratio);
      let accum = 0;
      let count = 0;
      for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
        accum += buffer[i];
        count++;
      }
      result[offsetResult] = count > 0 ? (accum / count) : 0;
      offsetResult++;
      offsetBuffer = nextOffsetBuffer;
    }
    return result;
  }

  function floatTo16BitPCM(floatBuf) {
    const out = new Int16Array(floatBuf.length);
    for (let i = 0; i < floatBuf.length; i++) {
      let s = Math.max(-1, Math.min(1, floatBuf[i]));
      out[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
    return out;
  }

  async function startMic() {
    if (micOn) return;

    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        channelCount: 1,
      }
    });

    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    sourceNode = audioCtx.createMediaStreamSource(mediaStream);

    // ScriptProcessor is deprecated but still widely supported and minimal for a prototype.
    // bufferSize 4096 is a common tradeoff.
    processorNode = audioCtx.createScriptProcessor(4096, 1, 1);

    // Avoid echo/feedback by routing through a zero gain node.
    zeroGain = audioCtx.createGain();
    zeroGain.gain.value = 0;

    processorNode.onaudioprocess = (e) => {
      const input = e.inputBuffer.getChannelData(0);
      const inSR = audioCtx.sampleRate;
      const mono16k = downsampleBuffer(input, inSR, TARGET_SR);
      const pcm16 = floatTo16BitPCM(mono16k);

      if (sending && ws && ws.readyState === WebSocket.OPEN) {
        ws.send(pcm16.buffer);
      }
    };

    sourceNode.connect(processorNode);
    processorNode.connect(zeroGain);
    zeroGain.connect(audioCtx.destination);

    micOn = true;
    micBtn.textContent = 'Mic OFF';
    
    if (ws && ws.readyState === WebSocket.OPEN) {
        sending = true;
        setStatus(`Mic Streaming ON. Sending ${TARGET_SR}Hz mono PCM16.`);
    } else {
        setStatus(`Mic ON (Local). Waiting for Qwen connection...`);
    }
  }

  async function stopMic() {
    if (!micOn) return;

    try { processorNode && processorNode.disconnect(); } catch (e) {}
    try { sourceNode && sourceNode.disconnect(); } catch (e) {}
    try { zeroGain && zeroGain.disconnect(); } catch (e) {}

    if (mediaStream) {
      for (const t of mediaStream.getTracks()) t.stop();
    }

    if (audioCtx) {
      try { await audioCtx.close(); } catch (e) {}
    }

    audioCtx = null;
    mediaStream = null;
    sourceNode = null;
    processorNode = null;
    zeroGain = null;

    micOn = false;
    sending = false; // Stop sending
    micBtn.textContent = 'Mic ON';
    setStatus('Mic OFF. Streaming stopped.');
  }

  function wsUrl() {
    const proto = location.protocol === 'https:' ? 'wss' : 'ws';
    return `${proto}://${location.host}/ws/pcm16`;
  }

  function ensurePlayCtx() {
    if (!playCtx) {
      playCtx = new (window.AudioContext || window.webkitAudioContext)();
    }
    if (playCtx.state === 'suspended') {
      // Must be called from a user gesture (e.g. button click)
      playCtx.resume();
    }
  }

  function pcm16ToFloat32(pcm16) {
    const f = new Float32Array(pcm16.length);
    for (let i = 0; i < pcm16.length; i++) {
      f[i] = Math.max(-1, Math.min(1, pcm16[i] / 32768));
    }
    return f;
  }

  function playPcm16le(arrayBuffer, meta) {
    if (!speakerOn) return;
    if (!meta || meta.audio_format !== 'pcm16le') {
      log('Got binary audio but missing/unsupported meta.');
      return;
    }

    ensurePlayCtx();

    const pcm16 = new Int16Array(arrayBuffer);
    const floatBuf = pcm16ToFloat32(pcm16);

    const sr = meta.audio_sample_rate || 24000;
    const ch = meta.channels || 1;

    // For now we downmix on server, so expect mono.
    const audioBuffer = playCtx.createBuffer(1, floatBuf.length, sr);
    audioBuffer.getChannelData(0).set(floatBuf);

    const src = playCtx.createBufferSource();
    src.buffer = audioBuffer;
    src.connect(playCtx.destination);
    src.start(0);
  }

  // New Function: Connect WebSocket for streaming (called when Mic is turned ON)
  function connectWebSocket() {
    return new Promise((resolve, reject) => {
        if (ws && ws.readyState === WebSocket.OPEN) {
            resolve();
            return;
        }

        ws = new WebSocket(wsUrl());
        ws.binaryType = 'arraybuffer';

        ws.onopen = () => {
            log('WS connected for streaming.');
            resolve();
        };

        ws.onmessage = (ev) => {
             // We can receive JSON (status/meta) or binary (PCM16LE).
            if (typeof ev.data === 'string') {
                try {
                const obj = JSON.parse(ev.data);
                if (obj && typeof obj === 'object') {
                    if (obj.type === 'talker_audio') {
                        pendingAudioMeta = obj;
                        if (obj.text_log) log('talker: ' + obj.text_log);
                        return;
                    }

                    if (obj.error) {
                        log('ERROR: ' + obj.error);
                    } else {
                        let line = `chunk #${obj.chunks ?? '?'} processed`;
                        if (obj.team_audio === false) line += ' | (team audio: not configured)';
                        log(line);
                    }
                } else {
                    log(String(ev.data));
                }
                } catch {
                log(String(ev.data));
                }
                return;
            }

            // Binary -> play if speaker enabled
            if (ev.data instanceof ArrayBuffer) {
                playPcm16le(ev.data, pendingAudioMeta);
                pendingAudioMeta = null;
                return;
            }
        };

        ws.onclose = () => {
            log('WS closed.');
            ws = null;
            sending = false;
            // If mic was on, turn it off visually (although stream is dead)
            if (micOn) {
                 stopMic();
                 log('Mic stopped due to connection close.');
            }
        };

        ws.onerror = (e) => {
            log('WS error.');
            reject(e);
        };
    });
  }

  // Modified: Call HTTP API to initialize model
  async function startQwen() {
    runBtn.disabled = true;
    setStatus('Initializing Qwen Model (This may take 10-20s)...');
    
    try {
        const res = await fetch('/start_qwen', { method: 'POST' });
        if (!res.ok) {
            const txt = await res.text();
            throw new Error(txt || res.statusText);
        }
        const data = await res.json();
        log(`✅ ${data.message}`);
        
        // Success
        setStatus('Model Ready. Click "Mic ON" to start streaming.');
        runBtn.textContent = 'Model Ready';
        runBtn.disabled = true; // No need to click again
        
        // Enable Controls
        micBtn.disabled = false;
        spkBtn.disabled = false;
        
    } catch (e) {
        log(`❌ Initialization Failed: ${e.message}`);
        setStatus('Initialization Failed. See log.');
        runBtn.disabled = false; // Allow retry
        alert(`Failed to initialize model: ${e.message}`);
    }
  }

  function stopQwen() {
     // Not used in this flow anymore properly, but good cleanup
    if (ws) ws.close();
  }

  micBtn.addEventListener('click', async () => {
    try {
      if (!micOn) {
          // Turn ON
          if (!ws) {
             setStatus('Connecting to Streaming Server...');
             await connectWebSocket();
          }
          await startMic();
      } else {
          // Turn OFF
          await stopMic();
          // Optional: Keep WS open? Or Close?
          // User said "Start websocket communication from then [mic on enabled]".
          // We'll keep it open to receive lagging audio.
      }
    } catch (e) {
      log('Mic error: ' + (e && e.message ? e.message : String(e)));
      setStatus('Mic/Connection error.');
    }
  });

  runBtn.addEventListener('click', () => {
     // Only for starting now
     startQwen();
  });

  spkBtn.addEventListener('click', () => {
    speakerOn = !speakerOn;
    if (speakerOn) {
      ensurePlayCtx();
      spkBtn.textContent = 'Speaker ON';
      log('Speaker ON.');
    } else {
      spkBtn.textContent = 'Speaker OFF';
      log('Speaker OFF.');
    }
  });
})();
</script>
</body>
</html>
