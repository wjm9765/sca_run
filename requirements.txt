fastapi>=0.110
uvicorn[standard]>=0.27
python-multipart>=0.0.9

# Local Qwen3-Omni inference (Transformers)
# NOTE: Install an appropriate PyTorch build for your environment separately.
transformers==4.57.3
accelerate>=0.26

# Optional but recommended for speed (GPU only):
# flash-attn
